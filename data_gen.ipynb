{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to test the generator function. Outputs .json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This version of the generator function has issues with the assert. See data_gen for the fixed version.\n",
    "# Issue: the assert breaks when features is not between 0 and 1.\n",
    "# Keep for validation purposes. Can call this to see if the shapes match up with the fixed version (it did for me!)\n",
    "\n",
    "# A GENERATOR FUNCTION, THE GENERATED OUTPUTS CHANGE AS THE CODE PROGRESSES\n",
    "# MORE SAMPLES ARE ADDED FOR EACH \"BATCH\" COMPLETED\n",
    "\n",
    "# Gets a fixed number of files to process based on the batch size\n",
    "# Then aggregates/concats TO INTERNAL LIST/state over entire dataset\n",
    "def data_gen_old(voc_list, mode = 'Train', sec_mode = 0):\n",
    "    # val_list = ['nus_MCUR_sing_04.hdf5', 'nus_ADIZ_read_01.hdf5', 'nus_JLEE_sing_05.hdf5','nus_JTAN_read_07.hdf5' ]\n",
    "\n",
    "    # import pdb;pdb.set_trace()\n",
    "\n",
    "    stat_file = h5py.File(config.stat_dir+'stats.hdf5', mode='r')\n",
    "\n",
    "    max_feat = np.array(stat_file[\"feats_maximus\"])\n",
    "    min_feat = np.array(stat_file[\"feats_minimus\"])\n",
    "\n",
    "    stat_file.close()\n",
    "\n",
    "\n",
    "    max_files_to_process = int(config.batch_size/config.samples_per_file)\n",
    "    # max_files_to_process = 1\n",
    "\n",
    "    if mode == \"Train\":\n",
    "        num_batches = config.batches_per_epoch_train\n",
    "        if sec_mode == 0:\n",
    "            file_list = voc_list\n",
    "\n",
    "    else: \n",
    "        # num_batches = config.batches_per_epoch_val\n",
    "        # file_list = val_list\n",
    "        return\n",
    "\n",
    "    for k in range(num_batches):\n",
    "        if sec_mode == 1:\n",
    "            if np.random.rand(1)<config.aug_prob:\n",
    "                file_list = voc_list\n",
    "            else:\n",
    "                file_list = voc_list\n",
    "        \n",
    "\n",
    "        feats_targs = []\n",
    "        targets_f0_1 = []\n",
    "        targets_singers = []\n",
    "        pho_targs = []\n",
    "\n",
    "        # start_time = time.time()\n",
    "        if k == num_batches-1 and mode ==\"Train\":\n",
    "            file_list = voc_list\n",
    "\n",
    "        for i in range(max_files_to_process):\n",
    "            #randomly choose some file to process\n",
    "            voc_index = np.random.randint(0,len(file_list))\n",
    "            voc_to_open = file_list[voc_index]\n",
    "            voc_file = h5py.File(config.voice_dir+voc_to_open, \"r\")\n",
    "            feats = np.array(voc_file['feats'])\n",
    "\n",
    "            f0 = feats[:,-2]\n",
    "\n",
    "            med = np.median(f0[f0 > 0])\n",
    "\n",
    "            f0[f0==0] = med\n",
    "\n",
    "            f0_nor = (f0 - min_feat[-2])/(max_feat[-2]-min_feat[-2])\n",
    "            \n",
    "\n",
    "            feats = (feats-min_feat)/(max_feat-min_feat)\n",
    "\n",
    "            feats[:,-2] = f0_nor\n",
    "\n",
    "\n",
    "            if voc_to_open.startswith('nus'):\n",
    "                if not  \"phonemes\" in voc_file:\n",
    "                    print(voc_file)\n",
    "                    Flag = False\n",
    "                else: \n",
    "                    Flag = True\n",
    "                    pho_target = np.array(voc_file[\"phonemes\"])\n",
    "                    singer_name = voc_to_open.split('_')[1]\n",
    "                    singer_index = config.singers.index(singer_name)\n",
    "                    print(\"singer\", singer_name, singer_index)\n",
    "            else:\n",
    "                Flag = False\n",
    "\n",
    "            # there are 6 samples per file\n",
    "            for j in range(config.samples_per_file):\n",
    "                    # randomly get a WINDOW of 128 frames for each file.\n",
    "                    # each 128 frames is a sample\n",
    "                    voc_idx = np.random.randint(0,len(feats)-config.max_phr_len)\n",
    "                    print(\"start\", voc_idx, \"end\", voc_idx+config.max_phr_len)\n",
    "                    targets_f0_1.append(f0_nor[voc_idx:voc_idx+config.max_phr_len])\n",
    "                    if Flag:\n",
    "                        pho_targs.append(pho_target[voc_idx:voc_idx+config.max_phr_len])\n",
    "                        targets_singers.append(singer_index)\n",
    "\n",
    "                    feats_targs.append(feats[voc_idx:voc_idx+config.max_phr_len])\n",
    "\n",
    "        targets_f0_1 = np.expand_dims(np.array(targets_f0_1), -1)\n",
    "\n",
    "        feats_targs = np.array(feats_targs)\n",
    "\n",
    "        assert feats_targs.max()<=1.0 and feats_targs.min()>=0.0\n",
    "\n",
    "        yield feats_targs, targets_f0_1, np.array(pho_targs), np.array(targets_singers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIXED VERSION OF DATA GEN\n",
    "# Objective: keep features to be between 0 and 1.\n",
    "# All the hdf5 files contain features that are not in 0-1, we want to keep only the samples (of 128 frames) that meet this limit.\n",
    "# While loop to reject samples that are not 0-1, and keep re-sampling up to 20 times.\n",
    "# If it still fails, skip to the next artist and loop back to the first person.\n",
    "\n",
    "# A GENERATOR FUNCTION, THE GENERATED OUTPUTS CHANGE AS THE CODE PROGRESSES\n",
    "# MORE SAMPLES ARE ADDED FOR EACH \"BATCH\" COMPLETED\n",
    "\n",
    "# Gets a fixed number of files to process based on the batch size\n",
    "# Then aggregates/concats TO INTERNAL LIST/state over entire dataset\n",
    "def data_gen(voc_list):\n",
    "\n",
    "    # print(voc_list)\n",
    "\n",
    "    stat_file = h5py.File(config.stat_dir+'stats.hdf5', mode='r')\n",
    "    max_feat = np.array(stat_file[\"feats_maximus\"])\n",
    "    min_feat = np.array(stat_file[\"feats_minimus\"])\n",
    "\n",
    "    stat_file.close()\n",
    "\n",
    "    max_files_to_process = int(config.batch_size/config.samples_per_file)\n",
    "    # max_files_to_process = 1\n",
    "\n",
    "    num_batches = config.batches_per_epoch_train\n",
    "    file_list = voc_list\n",
    "\n",
    "    # The outside number of batches is PAUSED for each iteration (k)\n",
    "    for k in range(num_batches):\n",
    "        feats_targs = []\n",
    "        targets_f0_1 = []\n",
    "        targets_singers = []\n",
    "        pho_targs = []\n",
    "\n",
    "        # maximum of about 5 files? to process\n",
    "        while len(feats_targs) < config.batch_size:\n",
    "            #randomly choose some file to process\n",
    "            voc_index = np.random.randint(0,len(file_list))\n",
    "            voc_to_open = file_list[voc_index]\n",
    "            voc_file = h5py.File(config.voice_dir + voc_to_open, \"r\")\n",
    "            feats = np.array(voc_file['feats'])\n",
    "\n",
    "            f0 = feats[:,-2]\n",
    "            med = np.median(f0[f0 > 0])\n",
    "            f0[f0==0] = med\n",
    "            f0_nor = (f0 - min_feat[-2])/(max_feat[-2]-min_feat[-2])\n",
    "\n",
    "            feats = (feats-min_feat)/(max_feat-min_feat)\n",
    "\n",
    "            feats[:,-2] = f0_nor\n",
    "\n",
    "\n",
    "            if voc_to_open.startswith('nus'):\n",
    "                if not  \"phonemes\" in voc_file:\n",
    "                    print(voc_file)\n",
    "                    Flag = False\n",
    "                else: \n",
    "                    Flag = True\n",
    "                    pho_target = np.array(voc_file[\"phonemes\"])\n",
    "                    singer_name = voc_to_open.split('_')[1]\n",
    "                    singer_index = config.singers.index(singer_name)\n",
    "            else:\n",
    "                Flag = False\n",
    "\n",
    "            # there are 6 samples per file\n",
    "            for j in range(config.samples_per_file):\n",
    "                # randomly get a WINDOW of 128 frames for each file.\n",
    "                # each 128 frames is a sample\n",
    "                broken = False\n",
    "                voc_idx = np.random.randint(0,len(feats)-config.max_phr_len)\n",
    "                \n",
    "                feat = feats[voc_idx:voc_idx+config.max_phr_len]\n",
    "                resample_count = 0\n",
    "                while feat.max()>1.0 or feat.min()<0.0:\n",
    "                    resample_count += 1\n",
    "                    voc_idx = np.random.randint(0,len(feats)-config.max_phr_len)\n",
    "                    feat = feats[voc_idx:voc_idx+config.max_phr_len]\n",
    "                    if resample_count > 20:\n",
    "                        broken = True\n",
    "                        # print(singer_name)\n",
    "                        break\n",
    "                \n",
    "                if broken:\n",
    "                    break\n",
    "                \n",
    "                targets_f0_1.append(f0_nor[voc_idx:voc_idx+config.max_phr_len])\n",
    "                if Flag:\n",
    "                    pho_targs.append(pho_target[voc_idx:voc_idx+config.max_phr_len])\n",
    "                    targets_singers.append(singer_index)\n",
    "\n",
    "                assert feat.max()<=1.0 and feat.min()>=0.0, \"chicken nigget\" \n",
    "                feats_targs.append(feat)\n",
    "\n",
    "                if len(feats_targs) == config.batch_size:\n",
    "                    break\n",
    "\n",
    "            # print(len(feats_targs))\n",
    "\n",
    "        # print(len(feats_targs))\n",
    "                        \n",
    "\n",
    "        targets_f0_1 = np.expand_dims(np.array(targets_f0_1), -1)\n",
    "\n",
    "        feats_targs = np.array(feats_targs)\n",
    "\n",
    "        assert feats_targs.max()<=1.0 and feats_targs.min()>=0.0, \"offending singers: \" + str(targets_singers) \n",
    "\n",
    "        yield feats_targs, targets_f0_1, np.array(pho_targs), np.array(targets_singers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_list = [x for x in os.listdir(config.voice_dir) if\n",
    "  x.endswith('.hdf5') and x.startswith('nus') and not x == 'nus_MCUR_sing_04.hdf5' and not x == 'nus_ADIZ_read_01.hdf5'\n",
    "  and not x == 'nus_JLEE_sing_05.hdf5' and not x == 'nus_JTAN_read_07.hdf5']\n",
    "\n",
    "# If you only want AZIZ uncomment this:\n",
    "# voc_list = ['nus_ADIZ_sing_01.hdf5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator is a generator function. Call next() for another batch of samples up to 100 times.\n",
    "gen = data_gen(voc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_targs, f0, phos, singers = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_dump(filename, data):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving processed batch data as CSV.\n",
    "\n",
    "json_dump(\"feats_targs.json\", feats_targs)\n",
    "json_dump(\"f0.json\", f0)\n",
    "json_dump(\"phonemes.json\", phos)\n",
    "json_dump(\"singers.json\", singers)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
