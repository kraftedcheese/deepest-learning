{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to test the generator function. Outputs .csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A GENERATOR FUNCTION, THE GENERATED OUTPUTS CHANGE AS THE CODE PROGRESSES\n",
    "# MORE SAMPLES ARE ADDED FOR EACH \"BATCH\" COMPLETED\n",
    "\n",
    "# Gets a fixed number of files to process based on the batch size\n",
    "# Then aggregates/concats TO INTERNAL LIST/state over entire dataset\n",
    "def data_gen(voc_list, mode = 'Train', sec_mode = 0):\n",
    "\n",
    "    # val_list = ['nus_MCUR_sing_04.hdf5', 'nus_ADIZ_read_01.hdf5', 'nus_JLEE_sing_05.hdf5','nus_JTAN_read_07.hdf5' ]\n",
    "\n",
    "    # import pdb;pdb.set_trace()\n",
    "\n",
    "    stat_file = h5py.File(config.stat_dir+'stats.hdf5', mode='r')\n",
    "\n",
    "    max_feat = np.array(stat_file[\"feats_maximus\"])\n",
    "    min_feat = np.array(stat_file[\"feats_minimus\"])\n",
    "\n",
    "    stat_file.close()\n",
    "\n",
    "\n",
    "    max_files_to_process = int(config.batch_size/config.samples_per_file)\n",
    "    # max_files_to_process = 1\n",
    "\n",
    "    if mode == \"Train\":\n",
    "        num_batches = config.batches_per_epoch_train\n",
    "        if sec_mode == 0:\n",
    "            file_list = voc_list\n",
    "\n",
    "    else: \n",
    "        # num_batches = config.batches_per_epoch_val\n",
    "        # file_list = val_list\n",
    "        return\n",
    "\n",
    "    for k in range(num_batches):\n",
    "        if sec_mode == 1:\n",
    "            if np.random.rand(1)<config.aug_prob:\n",
    "                file_list = voc_list\n",
    "            else:\n",
    "                file_list = voc_list\n",
    "        \n",
    "\n",
    "        feats_targs = []\n",
    "        targets_f0_1 = []\n",
    "        targets_singers = []\n",
    "        pho_targs = []\n",
    "\n",
    "        # start_time = time.time()\n",
    "        if k == num_batches-1 and mode ==\"Train\":\n",
    "            file_list = voc_list\n",
    "\n",
    "        for i in range(max_files_to_process):\n",
    "            #randomly choose some file to process\n",
    "            voc_index = np.random.randint(0,len(file_list))\n",
    "            voc_to_open = file_list[voc_index]\n",
    "            voc_file = h5py.File(config.voice_dir+voc_to_open, \"r\")\n",
    "            feats = np.array(voc_file['feats'])\n",
    "\n",
    "            f0 = feats[:,-2]\n",
    "\n",
    "            med = np.median(f0[f0 > 0])\n",
    "\n",
    "            f0[f0==0] = med\n",
    "\n",
    "            f0_nor = (f0 - min_feat[-2])/(max_feat[-2]-min_feat[-2])\n",
    "            \n",
    "\n",
    "            feats = (feats-min_feat)/(max_feat-min_feat)\n",
    "\n",
    "            feats[:,-2] = f0_nor\n",
    "\n",
    "\n",
    "            if voc_to_open.startswith('nus'):\n",
    "                if not  \"phonemes\" in voc_file:\n",
    "                    print(voc_file)\n",
    "                    Flag = False\n",
    "                else: \n",
    "                    Flag = True\n",
    "                    pho_target = np.array(voc_file[\"phonemes\"])\n",
    "                    singer_name = voc_to_open.split('_')[1]\n",
    "                    singer_index = config.singers.index(singer_name)\n",
    "                    print(\"singer\", singer_name, singer_index)\n",
    "            else:\n",
    "                Flag = False\n",
    "\n",
    "            # there are 6 samples per file\n",
    "            for j in range(config.samples_per_file):\n",
    "                    # randomly get a WINDOW of 128 frames for each file.\n",
    "                    # each 128 frames is a sample\n",
    "                    voc_idx = np.random.randint(0,len(feats)-config.max_phr_len)\n",
    "                    print(\"start\", voc_idx, \"end\", voc_idx+config.max_phr_len)\n",
    "                    targets_f0_1.append(f0_nor[voc_idx:voc_idx+config.max_phr_len])\n",
    "                    if Flag:\n",
    "                        pho_targs.append(pho_target[voc_idx:voc_idx+config.max_phr_len])\n",
    "                        targets_singers.append(singer_index)\n",
    "\n",
    "                    feats_targs.append(feats[voc_idx:voc_idx+config.max_phr_len])\n",
    "\n",
    "        targets_f0_1 = np.expand_dims(np.array(targets_f0_1), -1)\n",
    "\n",
    "        feats_targs = np.array(feats_targs)\n",
    "\n",
    "        assert feats_targs.max()<=1.0 and feats_targs.min()>=0.0\n",
    "\n",
    "        yield feats_targs, targets_f0_1, np.array(pho_targs), np.array(targets_singers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_list = [x for x in os.listdir(config.voice_dir) if\n",
    "  x.endswith('.hdf5') and x.startswith('nus') and not x == 'nus_MCUR_sing_04.hdf5' and not x == 'nus_ADIZ_read_01.hdf5'\n",
    "  and not x == 'nus_JLEE_sing_05.hdf5' and not x == 'nus_JTAN_read_07.hdf5']\n",
    "\n",
    "# If you only want AZIZ uncomment this:\n",
    "# voc_list = ['nus_ADIZ_sing_01.hdf5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = data_gen(voc_list, 'Train', sec_mode = 0)\n",
    "feats_targs, f0, phos, singers = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving processed batch data as CSV.\n",
    "\n",
    "np.savetxt(\"feats_targs.csv\", feats_targs, delimiter=\",\")\n",
    "np.savetxt(\"f0.csv\", f0, delimiter=\",\")\n",
    "np.savetxt(\"phonemes.csv\", phos, delimiter=\",\")\n",
    "np.savetxt(\"singers.csv\", singers, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
